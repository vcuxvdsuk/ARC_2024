{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings as wr\nwr.filterwarnings('ignore')\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport category_encoders as ce\nfrom collections import deque\n\n# sklearn imports\nimport sklearn\nimport json\n\nfrom scipy.stats import uniform\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\nfrom sklearn import metrics\nfrom sklearn import pipeline\nfrom sklearn import linear_model\nfrom sklearn import preprocessing\nfrom sklearn import neural_network\nfrom sklearn import model_selection\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import LeavePOut\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.feature_selection import SequentialFeatureSelector\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.neighbors import KNeighborsClassifier \n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import AgglomerativeClustering\n\nfrom tqdm.auto import tqdm\n\nrandom_seed = 42","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:25:02.911454Z","iopub.execute_input":"2024-08-23T13:25:02.911872Z","iopub.status.idle":"2024-08-23T13:25:05.583546Z","shell.execute_reply.started":"2024-08-23T13:25:02.911837Z","shell.execute_reply":"2024-08-23T13:25:05.582428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-23T13:25:05.585877Z","iopub.execute_input":"2024-08-23T13:25:05.586507Z","iopub.status.idle":"2024-08-23T13:25:05.595038Z","shell.execute_reply.started":"2024-08-23T13:25:05.586474Z","shell.execute_reply":"2024-08-23T13:25:05.593411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the JSON data\nwith open('/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json', 'r') as file:\n    solutions_data = json.load(file)\nwith open('/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json', 'r') as file:\n    challenges_data = json.load(file)\n\ntraining_challenges_df = pd.read_json(\"/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:25:05.596987Z","iopub.execute_input":"2024-08-23T13:25:05.597911Z","iopub.status.idle":"2024-08-23T13:25:06.080378Z","shell.execute_reply.started":"2024-08-23T13:25:05.597869Z","shell.execute_reply":"2024-08-23T13:25:06.079251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_dicts(dict1, dict2):\n    combined_dict = {}\n    \n    for key in dict1.keys():\n        if key in dict2:\n            combined_dict[key] = {\n                'solution': [{'output': dict1[key]}],\n                'test': dict2[key]['test'],\n                'train': dict2[key]['train']\n            }\n    \n    return combined_dict\ntraining_dict = combine_dicts(solutions_data, challenges_data)\ni=0\nfor key,value in enumerate(training_dict.items()):\n    if i<1:\n        print(f\"key is {key}: value is{value}\")\n        i += 1\n    else:break","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:25:06.083991Z","iopub.execute_input":"2024-08-23T13:25:06.084977Z","iopub.status.idle":"2024-08-23T13:25:06.095778Z","shell.execute_reply.started":"2024-08-23T13:25:06.084927Z","shell.execute_reply":"2024-08-23T13:25:06.094492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef create_dataframe(data):\n    records = []\n    \n    for id_key, id_value in data.items():\n        record = {}\n        record['id'] = id_key\n        record['solution'] = id_value['solution'][0]['output'][0]  # Assuming single solution\n        record['test'] = id_value['test'][0]['input']  # Assuming single test input\n\n        # Adding train inputs and outputs dynamically\n        for i, train_case in enumerate(id_value['train']):\n            record[f'train_input_{i+1}'] = train_case['input']\n            record[f'train_output_{i+1}'] = train_case['output']\n        \n        records.append(record)\n    \n    df = pd.DataFrame(records)\n    return df\n\n\ntransform_df = create_dataframe(training_dict)\ntransform_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:25:06.097311Z","iopub.execute_input":"2024-08-23T13:25:06.097714Z","iopub.status.idle":"2024-08-23T13:25:06.370458Z","shell.execute_reply.started":"2024-08-23T13:25:06.097680Z","shell.execute_reply":"2024-08-23T13:25:06.369295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## adding simple objects description columns","metadata":{}},{"cell_type":"code","source":"def find_shapes_without_wrap(input_grid):\n    from collections import deque\n\n    def bfs(start, num):\n        queue = deque([start])\n        visited[start[0]][start[1]] = True\n        shape_positions = [start]\n        \n        while queue:\n            x, y = queue.popleft()\n            for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n                nx, ny = x + dx, y + dy\n                if 0 <= nx < len(input_grid) and 0 <= ny < len(input_grid[0]) and not visited[nx][ny] and input_grid[nx][ny] == num:\n                    visited[nx][ny] = True\n                    queue.append((nx, ny))\n                    shape_positions.append((nx, ny))\n                    \n        return shape_positions\n    \n    shapes = []\n    visited = [[False] * len(row) for row in input_grid]\n    \n    for i in range(len(input_grid)):\n        for j in range(len(input_grid[0])):\n            if not visited[i][j]:\n                shape_num = input_grid[i][j]\n                shape_positions = bfs((i, j), shape_num)\n                shape_indices = [i * len(input_grid[0]) + j for i, j in shape_positions]\n                shape_size = len(shape_positions)\n                shapes.append([shape_indices, shape_size, shape_num])\n                \n    return shapes\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:25:06.372482Z","iopub.execute_input":"2024-08-23T13:25:06.372918Z","iopub.status.idle":"2024-08-23T13:25:06.385697Z","shell.execute_reply.started":"2024-08-23T13:25:06.372879Z","shell.execute_reply":"2024-08-23T13:25:06.384513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef find_shapes_with_wrap(input_grid):\n    rows, cols = len(input_grid), len(input_grid[0])\n    visited = [[False] * cols for _ in range(rows)]\n    shapes = []\n    \n    def bfs_with_wrap(start, num, input_grid, visited):\n        rows, cols = len(input_grid), len(input_grid[0])\n        queue = deque([start])\n        visited[start[0]][start[1]] = True\n        shape_positions = [start]\n\n        while queue:\n            x, y = queue.popleft()\n            for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n                nx, ny = (x + dx) % rows, (y + dy) % cols  # Wrap around using modulo\n                if not visited[nx][ny] and input_grid[nx][ny] == num:\n                    visited[nx][ny] = True\n                    queue.append((nx, ny))\n                    shape_positions.append((nx, ny))\n\n        return shape_positions\n\n    for i in range(rows):\n        for j in range(cols):\n            if not visited[i][j]:\n                num = input_grid[i][j]\n                shape_positions = bfs_with_wrap((i, j), num, input_grid, visited)\n                flat_positions = [x * cols + y for x, y in shape_positions]\n                shapes.append([flat_positions, len(flat_positions), num])\n\n    return shapes\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:25:06.387334Z","iopub.execute_input":"2024-08-23T13:25:06.387787Z","iopub.status.idle":"2024-08-23T13:25:06.403572Z","shell.execute_reply.started":"2024-08-23T13:25:06.387741Z","shell.execute_reply":"2024-08-23T13:25:06.402444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_shape_functions(transform_df):\n    for i in range(1, 11):\n        input_col = f'train_input_{i}'\n        output_col = f'train_output_{i}'\n\n        # Check if the column exists\n        if input_col in transform_df.columns and output_col in transform_df.columns:\n            \n            # Apply the function to specific columns only if the values are not null\n            mask_input = transform_df[input_col].notna()\n            mask_output = transform_df[output_col].notna()\n            \n            transform_df.loc[mask_input, f'shape_info_no_wrap_input_{i}'] = transform_df.loc[mask_input, input_col].apply(find_shapes_without_wrap)\n            transform_df.loc[mask_output, f'shape_info_no_wrap_output_{i}'] = transform_df.loc[mask_output, output_col].apply(find_shapes_without_wrap)\n\n            transform_df.loc[mask_input, f'shape_info_wrap_input_{i}'] = transform_df.loc[mask_input, input_col].apply(find_shapes_with_wrap)\n            transform_df.loc[mask_output, f'shape_info_wrap_output_{i}'] = transform_df.loc[mask_output, output_col].apply(find_shapes_with_wrap)\n\n    return transform_df\n\n# Apply the function to the DataFrame\ntransform_df = apply_shape_functions(transform_df)\n\n# Display the first 5 rows of the DataFrame\ntransform_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:25:06.405068Z","iopub.execute_input":"2024-08-23T13:25:06.405457Z","iopub.status.idle":"2024-08-23T13:25:09.346442Z","shell.execute_reply.started":"2024-08-23T13:25:06.405425Z","shell.execute_reply":"2024-08-23T13:25:09.345308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:25:09.347783Z","iopub.execute_input":"2024-08-23T13:25:09.348171Z","iopub.status.idle":"2024-08-23T13:25:09.353607Z","shell.execute_reply.started":"2024-08-23T13:25:09.348128Z","shell.execute_reply":"2024-08-23T13:25:09.352515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a dendrogram\nresult = [(i, j, transform_df[\"train_input_1\"][i][j]) for i in range(len(transform_df[\"train_input_1\"])) for j in range(len(transform_df[\"train_input_1\"][i]))]\ndata = np.array(result)\n\nlinked_data = sch.linkage(data, method='ward')\n\n# Create a dendrogram\nplt.figure()\ndn = sch.dendrogram(Z)\nplt.show()\n\n# Assign clusters\nfrom scipy.cluster.hierarchy import fcluster\nmax_d = 10  # set your threshold distance\nclusters = fcluster(Z, max_d, criterion='distance')\n\nprint(\"Cluster assignments:\", clusters)\n\n# Plot the data in 3D with cluster labels\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(data[:, 0], data[:, 1], data[:, 2], c=clusters, cmap='prism')  # color by cluster\nax.set_xlabel('X Label')\nax.set_ylabel('Y Label')\nax.set_zlabel('Z Label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T13:59:43.433183Z","iopub.execute_input":"2024-08-23T13:59:43.434228Z","iopub.status.idle":"2024-08-23T13:59:43.531939Z","shell.execute_reply.started":"2024-08-23T13:59:43.434189Z","shell.execute_reply":"2024-08-23T13:59:43.530601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}